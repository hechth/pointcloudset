{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of package\n",
    "\n",
    "First import the package, and pathlib which is required to handle files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lidar\n",
    "print(f\"package version: {lidar.__version__}\")\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the warning, which comes from the rospy package.\n",
    "\n",
    "If you are useing VS code and the devcontainer then everything is setup for you (recommended). Otherwise you can choose to use the Docker file in the .devcontainer folder or make your own virtual environment.\n",
    "\n",
    "If you geta ModuleNotFoundError for lidar make sure that you actuall installed the package. This can be done with \n",
    "\n",
    "$ pip install -e .   \n",
    "\n",
    "in the folder where setup.py is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a ROS .bag file into the lidar.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbag = Path().cwd().parent.joinpath(\"tests/testdata/test.bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = lidar.Dataset.from_file(testbag,topic=\"/os1_cloud_node/points\",keep_zeros=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads the bagfile into the Dataset.\n",
    "Dataset only reads frames from the bagfile if needed, in order to save memory and make it possible to work which huge bagfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see whats availble use \"tab\" to see the availble properties and methods. Alterantivly, use help(), dir(), and the documentation.\n",
    "Also shift tab is nice inside jupyter lab.\n",
    "\n",
    "\n",
    "Lets enquire the start and end time of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.end_time"
   ]
  },
  {
   "source": [
    "# Working with the whole dataset\n",
    "You can work with the whole dataset. Even if they are huge, since the package used parallel processing with dask in the background.\n",
    "So make sure that your docker or computer has access to as many CPU cores as possbile."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.min()"
   ]
  },
  {
   "source": [
    "The Dataset class supports the basic functions like min, max, mean and std. They all work on 3 different level: dataset, frame and point. Lets investigate the differences. The default is over the whole dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frame = testset.min(\"frame\")\n",
    "min_frame"
   ]
  },
  {
   "source": [
    "So now we have a pandas DataFrame which gives us the min values of each column for each frame. This can also be used for plotting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(min_frame,x=\"timestamp\", y=\"x min\")"
   ]
  },
  {
   "source": [
    "Now lets investigate on the point level."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_point = testset.min(\"point\")\n",
    "min_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.std(\"point\")"
   ]
  },
  {
   "source": [
    "So we got a DataFrame with the min value for each point of the whole Dataset. Note that the points are identified by the orginial_id. For some lidars this does not make sense since the points locations changes over time, so please think beforehand if its is usefull for your lidar. Nevertheless, for the Ouster lidars this can be used and is very usefull.\n",
    "\n",
    "Also note the \"N\" column which gives the count of the point over the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "All thes methods are based on the aggregate method similar to the one from pandas. It works also on \"dataset\", \"frame\" and \"point\" level. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.agg(\"min\",\"dataset\")"
   ]
  },
  {
   "source": [
    "testset.agg([\"min\",\"max\",\"std\",\"mean\"],\"point\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.agg({\"x\":[\"max\",\"min\"]},\"point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.agg({\"x\":\"max\"},\"point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Frames\n",
    "\n",
    "They are based on pandas dataframes and pyntcloud.\n",
    "This was necessary since, no pointcloud library currently support to store automotive lidar data which consists of more than just y,x,z and maybe R,G,B\n",
    "\n",
    "First grab the first frame in the dataset:"
   ]
  },
  {
   "source": [
    "## Getting a Frame from a dastaset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe = testset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(testframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of points can vary from frame to frame, since all zero elements are deltede on import (see option keep_zero in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testframe)"
   ]
  },
  {
   "source": [
    "## Reading from a Frame file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasfile = Path(\"../tests/testdata/diamond.las\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe2 = lidar.Frame.from_file(lasfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testframe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Tip: move the mouse over the points to get detailed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe.plot(color=\"intensity\", point_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot uses plotly as the backend, which can be rather time consuming. \n",
    "WARNING: delte the output cells with plotly plots, they make the file very big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with pointcouds\n",
    "The frame consists maily of the properties \"data\" and \"points\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So data contains everything as a pandas dataframe. With all its power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe.data.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a closer look a the points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe.points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So its a Pyntcloud object https://pyntcloud.readthedocs.io/en/latest/PyntCloud.html which in turn is also based on Dataframes with many methods for pointclouds.\n",
    "In order to access the dataframe use this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointcloud processing with build in methods\n",
    "Although you can do a lot with just data and points, on its own the Frame object has methods build in for processing, which in turn return a frame object. The use the power of dataframes, pyntcloud and open3d.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newframe = testframe.limit(\"x\",-5,5).limit(\"intensity\",400,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is now a smaller Frame with x ranging from -5 to  5, and with intenisties above 400. Processing steps can be chained together since the return a new Frame object."
   ]
  },
  {
   "source": [
    "You can also plot the nweframe and investiget it further with tooltips on each point."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newframe.plot(\"intensity\",hover_data=[\"range\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plane segmenation, Clustering and overlaying several plots\n",
    "Please not that not all processing methods are demonstrated here. For more infor please refer to the html documenation of the Frame class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plane = newframe.plane_segmentation(distance_threshold= 0.01,ransac_n= 3,num_iterations= 50, return_plane_model=True)\n",
    "print(len(plane))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters = newframe.get_cluster(eps=0.5, min_points= 10)\n",
    "cluster1 = newframe.take_cluster(1,clusters)\n",
    "cluster2 = newframe.take_cluster(2,clusters)\n",
    "print(len(cluster1))\n",
    "print(len(cluster2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cluster1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newframe.plot(color=None, overlay={\"Cluster 1\": cluster1,\"Cluster 2\": cluster2})"
   ]
  },
  {
   "source": [
    "# Applying functions to the whole dataset\n",
    "Now we can develop a pipeline and but everything together. The .agg method is powerfull but sometimes not flexible enouth. So with .apply you can apply a function to the whole dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_target(frame: lidar.Frame) -> lidar.Frame:\n",
    "    return frame.limit(\"x\",0,1).limit(\"y\",0,1)"
   ]
  },
  {
   "source": [
    "Note the typehints. They are importont as they are used to determine if the result can be a new dataset are not. If the function returns a Frame then the result is another dataset. This is very usefull to chain operations togeterh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.apply(isolate_target)"
   ]
  },
  {
   "source": [
    "So the result is another Dataset. Now we can chain things together"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_to_frame(frame: lidar.Frame, to_compare: lidar.Frame) -> lidar.Frame:\n",
    "    return frame.diff(\"frame\", to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = testset.apply(isolate_target).apply(diff_to_frame, to_compare=testset[0])"
   ]
  },
  {
   "source": [
    "Note that this uses lazy evaluation from dask and therfore the result is only calulated when needed. So you could develop a complex chain and then investigate the results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[1]"
   ]
  },
  {
   "source": [
    "Now we can inquire the resulte even futher by useing .agg from before"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.agg({\"x difference\":\"max\"},\"frame\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}